services:
  # ── API Application ─────────────────────────────────
  api:
    build:
      context: .
      dockerfile: .docker/Dockerfile.api
    ports:
      - "8000:8000"
    environment:
      # These env vars override what's in .env inside the container.
      # In Docker, services talk to each other by service name,
      # so POSTGRES_HOST is "postgres" (the service name below),
      # not "localhost".
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-snapenv}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - GITHUB_WEBHOOK_SECRET=${GITHUB_WEBHOOK_SECRET:-}
      - GITHUB_TOKEN=${GITHUB_TOKEN:-}
      - GITHUB_REPOSITORY=${GITHUB_REPOSITORY:-}
      - DEBUG=true
      - LOG_LEVEL=DEBUG
    depends_on:
      postgres:
        condition: service_healthy      # Wait for DB to be ready
      redis:
        condition: service_healthy
    # In development: mount source code for hot reload.
    # Changes to Python files are picked up without rebuilding.
    volumes:
      - ./src:/app/src
    # Override the default CMD for development (adds --reload)
    command: uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload

  # ── Celery Worker ───────────────────────────────────
  # Runs the same codebase as the API, but starts Celery instead of uvicorn.
  # Processes async tasks: deploy/destroy preview environments, poll statuses.
  worker:
    build:
      context: .
      dockerfile: .docker/Dockerfile.api
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-snapenv}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - GITHUB_TOKEN=${GITHUB_TOKEN:-}
      - GITHUB_REPOSITORY=${GITHUB_REPOSITORY:-}
      - ARGOCD_SERVER=${ARGOCD_SERVER:-https://localhost:8080}
      - ARGOCD_TOKEN=${ARGOCD_TOKEN:-}
      - DEBUG=true
      - LOG_LEVEL=DEBUG
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./src:/app/src
    # Start Celery worker instead of the API server.
    # --loglevel=info: show task execution logs
    # --concurrency=2: run up to 2 tasks in parallel
    # -Q default: listen on the "default" queue
    command: celery -A src.workers.celery_app worker --loglevel=info --concurrency=2 -Q default

  # ── Redis ───────────────────────────────────────────
  # Message broker for Celery. Tasks are queued here by the API
  # and picked up by the worker.
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  # ── Database ────────────────────────────────────────
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      # Create a volume so data persists across container restarts.
      - postgres_data:/var/lib/postgresql/data
      # Init script: creates the test database automatically.
      # Files in docker-entrypoint-initdb.d/ run on first container start.
      - ./scripts/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U preview -d preview_platform"] # CMD-SHELL is to execute the command using a shell
      start_period: 10s # During the 10 first seconds it will ignore failure
      interval: 10s # Run the check every 10s
      timeout: 5s # Fail if it takes longer than 5s
      retries: 5 # If it fails 5 times in a row mark container as unhealthy

volumes:
  postgres_data:
